{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e082286",
   "metadata": {},
   "source": [
    "# 6.- Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e4d4ef",
   "metadata": {},
   "source": [
    "Machine learning model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "487da977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries utilized\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#evaluating the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Libraries for the \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pandasgui import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e21b1a3",
   "metadata": {},
   "source": [
    "### Loading the reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c97599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17538 entries, 0 to 17537\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       17538 non-null  int64  \n",
      " 1   LocID            17538 non-null  int64  \n",
      " 2   Time             17538 non-null  int64  \n",
      " 3   TPopulation1Jan  17538 non-null  float64\n",
      " 4   PopDensity       17538 non-null  float64\n",
      " 5   PopSexRatio      17538 non-null  float64\n",
      " 6   MedianAgePop     17538 non-null  float64\n",
      " 7   PopGrowthRate    17538 non-null  float64\n",
      " 8   DoublingTime     17538 non-null  float64\n",
      " 9   MAC              17538 non-null  float64\n",
      " 10  SRB              17538 non-null  float64\n",
      " 11  CDR              17538 non-null  float64\n",
      " 12  NetMigrations    17538 non-null  float64\n",
      " 13  Location         17538 non-null  object \n",
      "dtypes: float64(10), int64(3), object(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Loading from the previously processed dataframe\n",
    "population_data_origin  = pd.read_csv('datasets/population_merged_reduced.csv',  sep=\",\",low_memory=False)\n",
    "\n",
    "# Display the DataFrame information including data types\n",
    "population_data_origin.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd573f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocID</th>\n",
       "      <th>Time</th>\n",
       "      <th>TPopulation1Jan</th>\n",
       "      <th>PopDensity</th>\n",
       "      <th>PopSexRatio</th>\n",
       "      <th>MedianAgePop</th>\n",
       "      <th>PopGrowthRate</th>\n",
       "      <th>DoublingTime</th>\n",
       "      <th>MAC</th>\n",
       "      <th>SRB</th>\n",
       "      <th>CDR</th>\n",
       "      <th>NetMigrations</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>1950</td>\n",
       "      <td>2229.322</td>\n",
       "      <td>86.8637</td>\n",
       "      <td>91.9472</td>\n",
       "      <td>18.3147</td>\n",
       "      <td>2.200</td>\n",
       "      <td>31.5067</td>\n",
       "      <td>30.995</td>\n",
       "      <td>102.5</td>\n",
       "      <td>23.546</td>\n",
       "      <td>-13.343</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>1951</td>\n",
       "      <td>2278.903</td>\n",
       "      <td>88.7571</td>\n",
       "      <td>92.1448</td>\n",
       "      <td>18.0842</td>\n",
       "      <td>2.114</td>\n",
       "      <td>32.7884</td>\n",
       "      <td>30.996</td>\n",
       "      <td>102.5</td>\n",
       "      <td>23.879</td>\n",
       "      <td>-13.217</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>1952</td>\n",
       "      <td>2327.593</td>\n",
       "      <td>90.6179</td>\n",
       "      <td>92.3191</td>\n",
       "      <td>17.8744</td>\n",
       "      <td>2.036</td>\n",
       "      <td>34.0446</td>\n",
       "      <td>31.026</td>\n",
       "      <td>102.5</td>\n",
       "      <td>23.815</td>\n",
       "      <td>-13.715</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>1953</td>\n",
       "      <td>2375.478</td>\n",
       "      <td>92.4508</td>\n",
       "      <td>92.4880</td>\n",
       "      <td>17.6693</td>\n",
       "      <td>1.969</td>\n",
       "      <td>35.2030</td>\n",
       "      <td>31.030</td>\n",
       "      <td>102.5</td>\n",
       "      <td>23.604</td>\n",
       "      <td>-14.962</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>1954</td>\n",
       "      <td>2422.721</td>\n",
       "      <td>94.2874</td>\n",
       "      <td>92.6503</td>\n",
       "      <td>17.4706</td>\n",
       "      <td>1.965</td>\n",
       "      <td>35.2747</td>\n",
       "      <td>31.036</td>\n",
       "      <td>102.5</td>\n",
       "      <td>23.347</td>\n",
       "      <td>-14.599</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocID  Time  TPopulation1Jan  PopDensity  PopSexRatio  MedianAgePop  \\\n",
       "0    108  1950         2229.322     86.8637      91.9472       18.3147   \n",
       "1    108  1951         2278.903     88.7571      92.1448       18.0842   \n",
       "2    108  1952         2327.593     90.6179      92.3191       17.8744   \n",
       "3    108  1953         2375.478     92.4508      92.4880       17.6693   \n",
       "4    108  1954         2422.721     94.2874      92.6503       17.4706   \n",
       "\n",
       "   PopGrowthRate  DoublingTime     MAC    SRB     CDR  NetMigrations Location  \n",
       "0          2.200       31.5067  30.995  102.5  23.546        -13.343  Burundi  \n",
       "1          2.114       32.7884  30.996  102.5  23.879        -13.217  Burundi  \n",
       "2          2.036       34.0446  31.026  102.5  23.815        -13.715  Burundi  \n",
       "3          1.969       35.2030  31.030  102.5  23.604        -14.962  Burundi  \n",
       "4          1.965       35.2747  31.036  102.5  23.347        -14.599  Burundi  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deleting first attribute garbage generated\n",
    "population_data_origin = population_data_origin.iloc[:, 1:]\n",
    "\n",
    "#show the dataframe\n",
    "population_data_origin.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc1954db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For modeling we do not need the location name varchar type\n",
    "population_data =  population_data_origin.drop(\"Location\", axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128d8bc0",
   "metadata": {},
   "source": [
    "## Applying Modeling algorithms\n",
    "\n",
    "Part of the questions I may need to ask involve my dependent variable, which is population size. However, I am specifically interested in making predictions based on years and country codes. While regression analysis is suitable for this task, I am also considering other algorithms to explore alternative approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a857e134",
   "metadata": {},
   "source": [
    "###  Multi-variable Linear Regression\n",
    "is a statistical modeling technique used to analyze the relationship between multiple independent variables (also known as predictors or features) and a single continuous dependent variable. It extends the concept of simple linear regression, which considers only one independent variable, to incorporate multiple predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddc3c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the independent variables (attributes) and the dependent variable\n",
    "X = population_data.drop('TPopulation1Jan', axis=1)  # The dependent variavle drop\n",
    "y = population_data['TPopulation1Jan']  # y for the dependent variable\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07f2fb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc0a6ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 6323442486.498052\n",
      "R-squared: 0.0668133501326188\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean squared error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# In the above code, X_train and y_train represent the independent variables and the corresponding dependent \n",
    "# variable from the training set, respectively. X_test and y_test represent the independent variables \n",
    "# and the corresponding dependent variable from the test set, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5588bcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-1.64036908e+01  6.47497980e+02 -1.10975530e+00  1.25414943e+02\n",
      " -5.97829033e+02  3.07743314e+03  2.65789187e+02 -7.61267615e+03\n",
      "  1.26701645e+04  1.58381051e+03 -5.67975392e+01]\n",
      "Intercept: -2399521.1002219487\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients (slopes) and intercept of the linear regression model\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb13536a",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory (LSTM) Networks: \n",
    " \n",
    "LSTM is a type of recurrent neural network (RNN) that can effectively model and predict sequences, including time series data. LSTM networks can capture long-term dependencies and are commonly used for time series forecasting tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09989d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "439/439 [==============================] - 4s 5ms/step - loss: 10073919488.0000\n",
      "Epoch 2/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10072924160.0000\n",
      "Epoch 3/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10072107008.0000\n",
      "Epoch 4/10\n",
      "439/439 [==============================] - 2s 4ms/step - loss: 10071321600.0000\n",
      "Epoch 5/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10070542336.0000\n",
      "Epoch 6/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10069781504.0000\n",
      "Epoch 7/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10069014528.0000\n",
      "Epoch 8/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10068255744.0000\n",
      "Epoch 9/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10067503104.0000\n",
      "Epoch 10/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10066738176.0000\n",
      "110/110 [==============================] - 1s 2ms/step\n",
      "110/110 [==============================] - 1s 2ms/step - loss: 7154476032.0000\n",
      "Test Loss: 7154476032.0\n"
     ]
    }
   ],
   "source": [
    "# Separate the independent variables (attributes) and the dependent variable\n",
    "X = population_data.drop('TPopulation1Jan', axis=1)  # Replace 'TPopulation1Jan' with the column name of your dependent variable\n",
    "y = population_data['TPopulation1Jan']  # Replace 'TPopulation1Jan' with the column name of your dependent variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape input data to fit the LSTM input shape [samples, time steps, features]\n",
    "X_train = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Create the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(units=1))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fefc50d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "439/439 [==============================] - 4s 5ms/step - loss: 10073896960.0000\n",
      "Epoch 2/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10072905728.0000\n",
      "Epoch 3/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10072099840.0000\n",
      "Epoch 4/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10071312384.0000\n",
      "Epoch 5/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10070542336.0000\n",
      "Epoch 6/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10069776384.0000\n",
      "Epoch 7/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10069018624.0000\n",
      "Epoch 8/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10068256768.0000\n",
      "Epoch 9/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10067493888.0000\n",
      "Epoch 10/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 10066731008.0000\n",
      "110/110 [==============================] - 1s 2ms/step\n",
      "110/110 [==============================] - 1s 2ms/step - loss: 7154458112.0000\n",
      "Test Loss: 7154458112.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data prepared in the following format:\n",
    "# X_train: Training features (input sequence)\n",
    "# y_train: Training labels (output/target)\n",
    "# X_test: Test features (input sequence)\n",
    "# y_test: Test labels (output/target)\n",
    "\n",
    "# Reshape input data to fit the LSTM input shape [samples, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1]*X_test.shape[2]))\n",
    "\n",
    "# Create the LSTM model\n",
    "model = Sequential()\n",
    "#model.add(LSTM(units=50, input_shape=(X_train.shape[1],)))\n",
    "model.add(LSTM(units=50, input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "model.add(Dense(units=1))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
