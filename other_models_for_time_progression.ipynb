{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f7bcf5",
   "metadata": {},
   "source": [
    "### Other Algorithms for analyzing progression of the population in Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea5b1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries utilized dataframes pandas, arrays numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#evaluating the model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "#modeling Algorithm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#scatter plot\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pandasgui import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c551916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17538 entries, 0 to 17537\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       17538 non-null  int64  \n",
      " 1   LocID            17538 non-null  int64  \n",
      " 2   Time             17538 non-null  int64  \n",
      " 3   TPopulation1Jan  17538 non-null  float64\n",
      " 4   PopDensity       17538 non-null  float64\n",
      " 5   PopSexRatio      17538 non-null  float64\n",
      " 6   MedianAgePop     17538 non-null  float64\n",
      " 7   PopGrowthRate    17538 non-null  float64\n",
      " 8   DoublingTime     17538 non-null  float64\n",
      " 9   MAC              17538 non-null  float64\n",
      " 10  SRB              17538 non-null  float64\n",
      " 11  CDR              17538 non-null  float64\n",
      " 12  NetMigrations    17538 non-null  float64\n",
      " 13  Location         17538 non-null  object \n",
      "dtypes: float64(10), int64(3), object(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Loading from the previously processed dataframe\n",
    "population_data_origin  = pd.read_csv('datasets/population_merged_reduced.csv',  sep=\",\",low_memory=False)\n",
    "\n",
    "# Display the DataFrame information including data types\n",
    "population_data_origin.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1d6d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocID</th>\n",
       "      <th>Time</th>\n",
       "      <th>TPopulation1Jan</th>\n",
       "      <th>PopDensity</th>\n",
       "      <th>PopSexRatio</th>\n",
       "      <th>MedianAgePop</th>\n",
       "      <th>PopGrowthRate</th>\n",
       "      <th>DoublingTime</th>\n",
       "      <th>MAC</th>\n",
       "      <th>SRB</th>\n",
       "      <th>CDR</th>\n",
       "      <th>NetMigrations</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>1950</td>\n",
       "      <td>2229.322</td>\n",
       "      <td>86.8637</td>\n",
       "      <td>91.9472</td>\n",
       "      <td>18.3147</td>\n",
       "      <td>2.200</td>\n",
       "      <td>31.5067</td>\n",
       "      <td>30.995</td>\n",
       "      <td>102.5</td>\n",
       "      <td>23.546</td>\n",
       "      <td>-13.343</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>1951</td>\n",
       "      <td>2278.903</td>\n",
       "      <td>88.7571</td>\n",
       "      <td>92.1448</td>\n",
       "      <td>18.0842</td>\n",
       "      <td>2.114</td>\n",
       "      <td>32.7884</td>\n",
       "      <td>30.996</td>\n",
       "      <td>102.5</td>\n",
       "      <td>23.879</td>\n",
       "      <td>-13.217</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>1952</td>\n",
       "      <td>2327.593</td>\n",
       "      <td>90.6179</td>\n",
       "      <td>92.3191</td>\n",
       "      <td>17.8744</td>\n",
       "      <td>2.036</td>\n",
       "      <td>34.0446</td>\n",
       "      <td>31.026</td>\n",
       "      <td>102.5</td>\n",
       "      <td>23.815</td>\n",
       "      <td>-13.715</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>1953</td>\n",
       "      <td>2375.478</td>\n",
       "      <td>92.4508</td>\n",
       "      <td>92.4880</td>\n",
       "      <td>17.6693</td>\n",
       "      <td>1.969</td>\n",
       "      <td>35.2030</td>\n",
       "      <td>31.030</td>\n",
       "      <td>102.5</td>\n",
       "      <td>23.604</td>\n",
       "      <td>-14.962</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>1954</td>\n",
       "      <td>2422.721</td>\n",
       "      <td>94.2874</td>\n",
       "      <td>92.6503</td>\n",
       "      <td>17.4706</td>\n",
       "      <td>1.965</td>\n",
       "      <td>35.2747</td>\n",
       "      <td>31.036</td>\n",
       "      <td>102.5</td>\n",
       "      <td>23.347</td>\n",
       "      <td>-14.599</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocID  Time  TPopulation1Jan  PopDensity  PopSexRatio  MedianAgePop  \\\n",
       "0    108  1950         2229.322     86.8637      91.9472       18.3147   \n",
       "1    108  1951         2278.903     88.7571      92.1448       18.0842   \n",
       "2    108  1952         2327.593     90.6179      92.3191       17.8744   \n",
       "3    108  1953         2375.478     92.4508      92.4880       17.6693   \n",
       "4    108  1954         2422.721     94.2874      92.6503       17.4706   \n",
       "\n",
       "   PopGrowthRate  DoublingTime     MAC    SRB     CDR  NetMigrations Location  \n",
       "0          2.200       31.5067  30.995  102.5  23.546        -13.343  Burundi  \n",
       "1          2.114       32.7884  30.996  102.5  23.879        -13.217  Burundi  \n",
       "2          2.036       34.0446  31.026  102.5  23.815        -13.715  Burundi  \n",
       "3          1.969       35.2030  31.030  102.5  23.604        -14.962  Burundi  \n",
       "4          1.965       35.2747  31.036  102.5  23.347        -14.599  Burundi  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deleting first attribute garbage generated\n",
    "population_data_origin = population_data_origin.iloc[:, 1:]\n",
    "\n",
    "#show the dataframe\n",
    "population_data_origin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f609715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For modeling we do not need the location name varchar type\n",
    "population_data =  population_data_origin.drop(\"Location\", axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ad58e",
   "metadata": {},
   "source": [
    "## Splitting the data in train and test sets by stratifying with a  Composite Primary Index ( CountryId, Year )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca2898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the independent variables (attributes) and the dependent variable\n",
    "X = population_data.drop('TPopulation1Jan', axis=1)  # The dependent variable dropped\n",
    "y = population_data['TPopulation1Jan']  # y for the dependent variable\n",
    "\n",
    "\n",
    "# Assuming 'primary_key_values' is a list of primary key values for each record\n",
    "primary_key_values = list(zip(population_data['LocID'], population_data['Time']))\n",
    "\n",
    "# Assuming 'train_primary_key_values' is a list of primary key values for the training set\n",
    "train_primary_key_values = list(set(zip(population_data['LocID'], population_data['Time'])))\n",
    "\n",
    "# Create a boolean mask to identify the indices that belong to the training set\n",
    "train_indices = [pk in train_primary_key_values for pk in primary_key_values]\n",
    "\n",
    "# Split the data into training and test sets based on the indices\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=train_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28610344",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory (LSTM) Networks: \n",
    " \n",
    "LSTM is a type of recurrent neural network (RNN) that can effectively model and predict sequences, including time series data. LSTM networks can capture long-term dependencies and are commonly used for time series forecasting tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e0cf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "439/439 [==============================] - 4s 6ms/step - loss: 9560025088.0000\n",
      "Epoch 2/10\n",
      "439/439 [==============================] - 2s 6ms/step - loss: 9559044096.0000\n",
      "Epoch 3/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 9558251520.0000\n",
      "Epoch 4/10\n",
      "439/439 [==============================] - 2s 5ms/step - loss: 9557473280.0000\n",
      "Epoch 5/10\n",
      "439/439 [==============================] - 2s 6ms/step - loss: 9556697088.0000\n",
      "Epoch 6/10\n",
      "439/439 [==============================] - 2s 6ms/step - loss: 9555928064.0000\n",
      "Epoch 7/10\n",
      "439/439 [==============================] - 2s 6ms/step - loss: 9555179520.0000\n",
      "Epoch 8/10\n",
      "439/439 [==============================] - 2s 6ms/step - loss: 9554429952.0000\n",
      "Epoch 9/10\n",
      "439/439 [==============================] - 2s 6ms/step - loss: 9553677312.0000\n",
      "Epoch 10/10\n",
      "439/439 [==============================] - 2s 6ms/step - loss: 9552932864.0000\n",
      "110/110 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create the LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(units=50, input_shape=(X_train.shape[1], 1)))\n",
    "model_lstm.add(Dense(units=1))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model_lstm.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model_lstm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "#loss = model.evaluate(X_test, y_test)\n",
    "#print(\"Test Loss:\", loss)\n",
    "train_r2_svr = r2_score(y_train, y_train)\n",
    "test_r2_svr = r2_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e3971",
   "metadata": {},
   "source": [
    "### ARIMA - AutoRegressive Integrated Moving Average. \n",
    "\n",
    "Well known time series forecasting method used to model and predict time-dependent data. ARIMA models are designed to capture different aspects of time series data, including trends, seasonality, and noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c03244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Provided exogenous values are not of the appropriate shape. Required (5, 10), got ().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:1775\u001b[0m, in \u001b[0;36mMLEModel._validate_out_of_sample_exog\u001b[1;34m(self, exog, out_of_sample)\u001b[0m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     exog \u001b[38;5;241m=\u001b[39m \u001b[43mexog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequired_exog_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (5,10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 34\u001b[0m\n\u001b[0;32m     23\u001b[0m X_future_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_2030\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m],  \n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_2031\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m],  \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_2035\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     30\u001b[0m }    \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# # Make predictions for the future using the ARIMA model\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m y_future_pred \u001b[38;5;241m=\u001b[39m \u001b[43marima_model_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfuture_time_points\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_future_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_future_pred)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\base\\wrapper.py:113\u001b[0m, in \u001b[0;36mmake_wrapper.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(func(results, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), how[\u001b[38;5;241m0\u001b[39m], how[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how:\n\u001b[1;32m--> 113\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(func(results, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), how)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3442\u001b[0m, in \u001b[0;36mMLEResults.forecast\u001b[1;34m(self, steps, **kwargs)\u001b[0m\n\u001b[0;32m   3440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3441\u001b[0m     end \u001b[38;5;241m=\u001b[39m steps\n\u001b[1;32m-> 3442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnobs, end\u001b[38;5;241m=\u001b[39mend, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3403\u001b[0m, in \u001b[0;36mMLEResults.predict\u001b[1;34m(self, start, end, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m   3357\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3358\u001b[0m \u001b[38;5;124;03mIn-sample prediction and out-of-sample forecasting\u001b[39;00m\n\u001b[0;32m   3359\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3400\u001b[0m \u001b[38;5;124;03m    including confidence intervals.\u001b[39;00m\n\u001b[0;32m   3401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3402\u001b[0m \u001b[38;5;66;03m# Perform the prediction\u001b[39;00m\n\u001b[1;32m-> 3403\u001b[0m prediction_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_prediction(start, end, dynamic, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction_results\u001b[38;5;241m.\u001b[39mpredicted_mean\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3302\u001b[0m, in \u001b[0;36mMLEResults.get_prediction\u001b[1;34m(self, start, end, dynamic, index, exog, extend_model, extend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   3299\u001b[0m     extend_model \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   3300\u001b[0m                     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_results\u001b[38;5;241m.\u001b[39mtime_invariant)\n\u001b[0;32m   3301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_of_sample \u001b[38;5;129;01mand\u001b[39;00m extend_model:\n\u001b[1;32m-> 3302\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_get_extension_time_varying_matrices(\n\u001b[0;32m   3303\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, exog, out_of_sample, extend_kwargs,\n\u001b[0;32m   3304\u001b[0m         transformed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, includes_fixed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3306\u001b[0m \u001b[38;5;66;03m# Make sure the model class has the current parameters\u001b[39;00m\n\u001b[0;32m   3307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, transformed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, includes_fixed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1718\u001b[0m, in \u001b[0;36mSARIMAX._get_extension_time_varying_matrices\u001b[1;34m(self, params, exog, out_of_sample, extend_kwargs, transformed, includes_fixed, **kwargs)\u001b[0m\n\u001b[0;32m   1708\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1709\u001b[0m \u001b[38;5;124;03mGet time-varying state space system matrices for extended model\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;124;03mspecial handling in the `simple_differencing=True` case.\u001b[39;00m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1717\u001b[0m \u001b[38;5;66;03m# Get the appropriate exog for the extended sample\u001b[39;00m\n\u001b[1;32m-> 1718\u001b[0m exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_out_of_sample_exog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_of_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[38;5;66;03m# Get the tmp endog, exog\u001b[39;00m\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimple_differencing:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:1777\u001b[0m, in \u001b[0;36mMLEModel._validate_out_of_sample_exog\u001b[1;34m(self, exog, out_of_sample)\u001b[0m\n\u001b[0;32m   1775\u001b[0m         exog \u001b[38;5;241m=\u001b[39m exog\u001b[38;5;241m.\u001b[39mreshape(required_exog_shape)\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m-> 1777\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProvided exogenous values are not of the\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1778\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m appropriate shape. Required \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1779\u001b[0m                          \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mstr\u001b[39m(required_exog_shape),\n\u001b[0;32m   1780\u001b[0m                             \u001b[38;5;28mstr\u001b[39m(exog\u001b[38;5;241m.\u001b[39mshape)))\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_exog \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Provided exogenous values are not of the appropriate shape. Required (5, 10), got ()."
     ]
    }
   ],
   "source": [
    "#' Time' is the column representing the year\n",
    "population_data['Time'] = pd.to_datetime(population_data['Time'], format='%Y')\n",
    "population_data.set_index('Time', inplace=True)\n",
    "\n",
    "# Resample or interpolate missing data (if needed)\n",
    "#population_data = population_data.resample('Y').mean()  # Resample to yearly frequency and calculate the mean for missing years\n",
    "\n",
    "X = population_data.drop('TPopulation1Jan', axis=1)  # Independent variables\n",
    "y = population_data['TPopulation1Jan']  # Dependent variable\n",
    "\n",
    "\n",
    "arima_order = (1, 1, 1)  # Example ARIMA order (p, d, q)\n",
    "arima_model = ARIMA(y, order=arima_order, exog=X)\n",
    "arima_model_fit = arima_model.fit()\n",
    "\n",
    "#Generate future time points\n",
    "future_time_points = pd.date_range(start='2030-01-01', end='2035-01-01', freq='Y')\n",
    "\n",
    "\n",
    "# Assuming you have the corresponding independent variables for the future time points in \n",
    "# all the independent variables with the exception of Time that has been converted in index  \n",
    "#'LocID','Time','PopDensity','PopSexRatio','MedianAgePop','PopGrowthRate','DoublingTime','MAC','SRB','CDR','NetMigrations'\n",
    "X_future_data = {\n",
    "    'feature_2030': [0,0,0,0,0,0,0,0,0,0],  \n",
    "    'feature_2031': [0,0,0,0,0,0,0,0,0,0],  \n",
    "    'feature_2032': [0,0,0,0,0,0,0,0,0,0],\n",
    "    'feature_2033': [0,0,0,0,0,0,0,0,0,0],\n",
    "    'feature_2034': [0,0,0,0,0,0,0,0,0,0],\n",
    "    'feature_2035': [0,0,0,0,0,0,0,0,0,0]\n",
    "}    \n",
    "        \n",
    "\n",
    "# # Make predictions for the future using the ARIMA model\n",
    "y_future_pred = arima_model_fit.forecast(steps=len(future_time_points), exog=X_future_data ).values\n",
    "\n",
    "print(y_future_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e679ef3",
   "metadata": {},
   "source": [
    "The previous program is Throwing error, because the values are not within the range of the the valid values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570c2c7",
   "metadata": {},
   "source": [
    "Resolving the issue of providing values for the indepenent variables\n",
    "\n",
    "    Historical Averages: Calculate the historical averages for each independent variable and use these averages as constant values for the future time points. While this approach assumes that the future values will be similar to historical averages, it can serve as a simple baseline.\n",
    "\n",
    "    Seasonal Decomposition: If your data exhibits seasonal patterns, you can use seasonal decomposition techniques to identify the seasonal component and then use this component to estimate future values. For example, you can use seasonal decomposition of time series (STL) or other decomposition methods to capture seasonal patterns and then extrapolate them into the future.\n",
    "\n",
    "    Forecasting Models: Use forecasting models for each independent variable to predict their future values. For example, you can use autoregressive integrated moving average (ARIMA) models or other time series forecasting techniques to predict the future values of each feature. This approach takes into account the temporal dependencies in the data.\n",
    "\n",
    "    Machine Learning: Train machine learning models to predict the independent variables based on historical data. Depending on the nature of your data, you can use regression models or time series forecasting algorithms to make predictions for the future time points.\n",
    "\n",
    "    Domain Expertise: If you have domain knowledge or access to subject matter experts, you can consult them to make reasonable assumptions about the future values of the independent variables based on their expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785195ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
